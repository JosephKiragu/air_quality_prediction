lightgbm_model:
  parameters:
    objective: 'regression'
    metric: 'rmse'
    boosting_type: 'gbdt'
    num_leaves: 31
    learning_rate: 0.1
    n_estimators: 100
    subsample: 0.8
    colsample_bytree: 0.8
    reg_alpha: 0
    reg_lambda: 0
    random_state: 149
    
  train_params:
    # early_stopping_rounds: 10
    verbose: True

  hyperparameter_tuning:
    enable: True
    method: 'random_search'
    n_iter: 50
    param_grid:
      num_leaves: [15,31,63,127]
      learning_rate: [0.01, 0.05, 0.1, 0.2]
      n_estimators: [50, 100, 150, 200]
      subsample: [0.6, 0.7, 0.8, 0.9]
      colsample_bytree: [0.6, 0.7, 0.8, 0.9]
      reg_alpha: [0, 0.1, 0.5, 1]
      reg_lambda: [0, 0.1, 0.5, 1]
    scoring: 'neg_mean_squared_error'
    random_state: 149

  train:
    train_data_path: 'data/processed/Train_data_engineered.csv'
    test_data_path: 'data/processed/Test_data_engineered.csv'

  output:
    model_output_path: 'outputs/models/lightgbm_model.pkl'
    predictiom_output_path: 'outputs/predictions/lightgbm_predictions.csv'

  model_saving:
    enable: True
    directory: 'outputs/models'
    filename: 'tuned_lightgbm_model.pkl'